{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.0935, -0.1234, -0.1659, -0.1449,  0.1550],\n",
      "          [-0.0472, -0.1853, -0.1347,  0.0652, -0.0466],\n",
      "          [ 0.0337,  0.0468,  0.0887,  0.1281,  0.1893],\n",
      "          [ 0.1251,  0.0382,  0.0152, -0.0964, -0.1670],\n",
      "          [-0.0812, -0.1393,  0.1549,  0.1626,  0.1312]]],\n",
      "\n",
      "\n",
      "        [[[-0.1990, -0.1763, -0.0378,  0.1835, -0.1818],\n",
      "          [ 0.1413, -0.1463, -0.1652, -0.1004,  0.0222],\n",
      "          [ 0.0883, -0.1975, -0.1320, -0.1711, -0.1534],\n",
      "          [-0.1427, -0.0447, -0.0949, -0.0819,  0.0715],\n",
      "          [ 0.1211,  0.1461,  0.0729,  0.1633,  0.1005]]],\n",
      "\n",
      "\n",
      "        [[[-0.1582,  0.0401, -0.1298, -0.0755,  0.1476],\n",
      "          [-0.0263, -0.0713,  0.0220,  0.0936,  0.0173],\n",
      "          [ 0.0956,  0.1053,  0.0343, -0.1279, -0.0160],\n",
      "          [ 0.1003,  0.0375,  0.0306, -0.1645,  0.0052],\n",
      "          [ 0.1928,  0.1258, -0.1043, -0.0711,  0.1627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0954,  0.0985, -0.1219, -0.1319,  0.1388],\n",
      "          [ 0.0910,  0.1240,  0.0067,  0.0341, -0.0991],\n",
      "          [ 0.0418,  0.1695, -0.1444,  0.0193, -0.0564],\n",
      "          [-0.0865, -0.0932,  0.0787,  0.0143, -0.1065],\n",
      "          [-0.0765,  0.0152, -0.1548,  0.0139,  0.1259]]],\n",
      "\n",
      "\n",
      "        [[[-0.1023, -0.0909,  0.0262, -0.0824,  0.1142],\n",
      "          [ 0.1254,  0.1825, -0.1550,  0.0788, -0.1153],\n",
      "          [ 0.0392,  0.1403,  0.1647, -0.0457, -0.1780],\n",
      "          [-0.0053,  0.0691,  0.0939,  0.0184, -0.0154],\n",
      "          [ 0.0467, -0.0909,  0.0207,  0.0138,  0.0457]]],\n",
      "\n",
      "\n",
      "        [[[-0.0417,  0.1273, -0.0579,  0.1391,  0.0998],\n",
      "          [-0.0095, -0.1518, -0.1097, -0.1484,  0.1688],\n",
      "          [-0.1962,  0.1726,  0.1366,  0.1106, -0.1823],\n",
      "          [-0.0667,  0.0006,  0.0253,  0.1598, -0.1613],\n",
      "          [-0.1568, -0.1783,  0.0039,  0.0610,  0.1502]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1222, -0.0948, -0.0435, -0.1181, -0.0177,  0.0705],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-1.8495e-02, -1.3178e-02, -7.2771e-02,  2.9391e-02, -4.6027e-02],\n",
      "          [ 1.0989e-02,  3.7268e-02, -1.3043e-02, -3.0719e-02,  1.6476e-02],\n",
      "          [ 6.8050e-02,  8.7869e-03,  4.0689e-02, -2.2616e-02, -1.9505e-02],\n",
      "          [ 1.0153e-02, -5.1746e-03,  5.3064e-02, -2.6240e-02,  6.1485e-02],\n",
      "          [-1.7283e-02, -3.6754e-02,  5.7643e-02,  1.8894e-02, -4.4895e-02]],\n",
      "\n",
      "         [[ 1.0569e-02, -4.2539e-02,  3.2158e-02, -5.9464e-02, -4.2225e-02],\n",
      "          [ 1.0103e-02, -2.1218e-02, -1.2724e-02,  1.2799e-02, -7.5240e-02],\n",
      "          [ 2.0366e-02, -4.2701e-02, -7.0317e-02, -2.6312e-02, -1.1103e-02],\n",
      "          [ 2.8632e-03, -2.9381e-02, -6.1822e-02, -2.5524e-02,  6.5515e-02],\n",
      "          [ 6.6811e-02, -6.2851e-02, -5.2973e-02,  4.7801e-02, -2.1890e-02]],\n",
      "\n",
      "         [[ 2.6577e-02, -5.1481e-04, -4.5425e-02,  2.3854e-02,  5.2834e-02],\n",
      "          [-8.0928e-02, -4.9648e-02,  1.9942e-02,  5.3335e-02, -4.1140e-02],\n",
      "          [-3.9380e-03, -6.1723e-02, -5.6504e-02,  7.1588e-02, -8.4150e-03],\n",
      "          [-2.5558e-02, -7.6924e-02, -7.6190e-02, -1.1428e-02,  1.8886e-02],\n",
      "          [ 1.6769e-02, -6.9656e-02, -6.2394e-02, -5.0860e-02,  7.1501e-02]],\n",
      "\n",
      "         [[-1.7155e-02, -7.4136e-02,  7.2054e-02, -7.8067e-02, -1.3471e-02],\n",
      "          [ 6.0498e-02, -5.6385e-02, -3.7611e-02, -3.6485e-02, -7.2586e-02],\n",
      "          [ 2.6158e-02, -4.0075e-02,  4.8460e-03,  4.1348e-02,  6.8836e-02],\n",
      "          [-4.0687e-02, -3.3285e-02, -4.7303e-02, -2.6681e-04, -5.9602e-03],\n",
      "          [ 2.9984e-02, -6.6492e-03,  1.2643e-02,  4.4712e-02,  1.7090e-03]],\n",
      "\n",
      "         [[ 5.0401e-02, -5.4171e-02,  5.6852e-02,  6.8022e-02, -2.1868e-02],\n",
      "          [-4.4246e-03,  3.6315e-03, -4.5835e-02, -4.8250e-02,  4.0836e-02],\n",
      "          [-5.1325e-02, -4.4587e-02,  2.7321e-02, -5.2078e-03,  6.8298e-02],\n",
      "          [-1.5085e-02, -7.3280e-02, -6.1087e-02, -3.5755e-02, -1.0434e-03],\n",
      "          [-5.1240e-02, -2.0065e-02, -2.3120e-02,  3.1826e-02, -5.3321e-02]],\n",
      "\n",
      "         [[-6.1876e-02, -3.3053e-02,  5.0219e-02, -7.2721e-02,  3.1964e-02],\n",
      "          [ 3.3171e-02, -4.3449e-02, -3.3587e-02,  1.4588e-02, -1.9220e-02],\n",
      "          [ 2.2477e-02,  7.1358e-02, -7.4581e-02, -6.2574e-02, -4.9041e-02],\n",
      "          [ 1.7734e-02,  5.4958e-02,  6.0586e-03,  4.5468e-02, -3.9394e-02],\n",
      "          [-6.3553e-02, -1.3419e-02, -1.3590e-02,  7.1172e-02, -5.9884e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1857e-02, -7.7477e-02, -2.7726e-02, -6.2613e-02,  2.1835e-02],\n",
      "          [ 4.3947e-02,  6.0420e-02,  3.4173e-02, -2.6032e-02,  1.1186e-02],\n",
      "          [-7.4363e-02,  5.0636e-04, -3.6164e-02,  2.5792e-02, -4.1533e-02],\n",
      "          [-7.1821e-02, -1.9770e-02,  6.6987e-02, -6.6818e-02,  2.0156e-02],\n",
      "          [-7.0226e-02, -5.6073e-03, -9.3048e-03,  3.5642e-02, -1.3494e-02]],\n",
      "\n",
      "         [[-7.9894e-02,  6.3187e-02, -4.3117e-02, -6.4458e-02,  5.4648e-02],\n",
      "          [-5.9401e-02, -1.4400e-02,  7.9091e-02, -6.8263e-02,  6.5513e-02],\n",
      "          [-2.5729e-02, -8.0200e-02, -5.7550e-02, -3.3688e-02, -3.2575e-03],\n",
      "          [ 2.3535e-02,  1.1216e-02,  7.0853e-02, -7.3685e-02, -7.5301e-02],\n",
      "          [-7.1498e-02, -3.1001e-02,  4.6282e-02, -1.9331e-02, -7.5296e-02]],\n",
      "\n",
      "         [[-5.2082e-02, -7.1607e-02,  5.5699e-02, -4.3142e-02, -5.8474e-02],\n",
      "          [ 3.0314e-02,  4.2341e-02,  2.6457e-02,  3.4712e-02,  8.0462e-03],\n",
      "          [-1.9873e-02,  7.6123e-02,  5.2215e-02, -6.7840e-02,  2.0115e-02],\n",
      "          [-6.1138e-02,  1.8097e-02, -5.9962e-02, -2.8724e-02, -3.8241e-02],\n",
      "          [-5.2509e-02, -4.6117e-03,  5.2920e-02,  7.6711e-02,  2.1211e-02]],\n",
      "\n",
      "         [[ 4.6546e-03, -4.6699e-02, -4.6614e-02,  5.1432e-02, -7.8134e-02],\n",
      "          [-5.0354e-02, -1.0109e-02, -5.9242e-02,  1.5627e-03, -8.0119e-02],\n",
      "          [-1.1095e-02,  6.9240e-02,  4.0031e-03, -5.7475e-02, -4.7780e-02],\n",
      "          [ 3.7858e-02, -6.1312e-02, -6.3988e-02,  1.9409e-02,  3.1578e-02],\n",
      "          [ 6.4376e-02, -1.8737e-02,  2.4094e-02, -7.0829e-02, -7.7322e-02]],\n",
      "\n",
      "         [[ 6.6751e-02,  7.9408e-02,  3.7687e-02, -6.3506e-02, -2.6972e-02],\n",
      "          [ 1.9721e-02,  6.9106e-02,  6.6046e-03, -7.9624e-03, -1.0478e-02],\n",
      "          [-4.8499e-03, -3.2562e-02,  5.7409e-02, -6.2281e-02,  7.0535e-03],\n",
      "          [ 5.9280e-02,  3.9852e-02,  1.9876e-02,  7.9340e-02,  6.9851e-02],\n",
      "          [ 1.3835e-02, -3.7033e-02,  6.3440e-02, -7.1128e-02,  1.7253e-02]],\n",
      "\n",
      "         [[ 6.1855e-02,  7.3947e-02,  6.0920e-02, -4.7794e-02, -2.1788e-02],\n",
      "          [-4.3847e-02, -4.6322e-02, -6.7624e-02, -5.8397e-02,  3.7480e-02],\n",
      "          [ 5.1918e-02,  5.3505e-02,  7.1678e-02, -3.9700e-02,  1.7887e-02],\n",
      "          [-5.7960e-04,  1.0244e-02, -3.1047e-02, -3.6469e-02,  3.2208e-02],\n",
      "          [ 5.9440e-02,  6.1783e-02, -6.4073e-02,  4.2409e-02, -2.7506e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9381e-03, -4.6641e-03,  3.6858e-02,  5.6893e-05, -2.2207e-02],\n",
      "          [ 3.5235e-02,  5.4028e-02, -7.0088e-03,  5.7392e-02, -1.9028e-02],\n",
      "          [-1.5597e-03,  3.5970e-02,  3.5116e-03, -3.7945e-02, -2.4204e-02],\n",
      "          [ 6.8641e-02,  4.7028e-02,  8.0123e-02,  2.3702e-02, -2.0482e-02],\n",
      "          [-1.5548e-02, -4.1537e-02, -7.8896e-02, -8.0869e-02,  2.9217e-02]],\n",
      "\n",
      "         [[ 6.1811e-03, -5.8560e-03, -2.4042e-02,  4.6320e-02, -3.5369e-03],\n",
      "          [ 4.4460e-02,  4.9225e-02, -4.9793e-02, -3.6962e-02, -1.9114e-02],\n",
      "          [-1.3262e-02, -2.2444e-02, -3.7923e-02, -4.9770e-02, -7.9986e-02],\n",
      "          [ 1.2605e-02,  6.6930e-02, -4.2282e-02,  5.0027e-02,  2.3539e-02],\n",
      "          [ 1.0758e-02, -4.2422e-03,  5.0475e-02, -4.3442e-02, -8.1467e-02]],\n",
      "\n",
      "         [[ 8.1259e-03, -3.3329e-02, -2.0362e-02,  8.1238e-02,  9.6260e-03],\n",
      "          [-4.5648e-02, -6.7339e-02, -3.9016e-02, -5.2508e-03,  1.2723e-02],\n",
      "          [ 3.6489e-02,  6.7297e-02, -1.7475e-02,  8.7959e-03, -5.8483e-02],\n",
      "          [-2.7501e-02, -5.1545e-02,  6.2010e-02, -7.4397e-02,  7.4312e-02],\n",
      "          [ 7.9137e-02, -7.0354e-02, -5.0212e-02, -3.4717e-02, -6.3579e-02]],\n",
      "\n",
      "         [[ 7.3830e-02,  7.0380e-02,  4.2864e-02, -7.6604e-02, -4.1199e-02],\n",
      "          [-7.4684e-02,  4.2854e-02,  1.3990e-02, -5.4606e-02,  4.7763e-02],\n",
      "          [-9.0052e-03,  3.2796e-02, -3.4173e-02, -6.5715e-02,  7.4577e-02],\n",
      "          [-5.3833e-02, -7.0647e-02, -2.0596e-02, -7.1236e-03,  6.6440e-03],\n",
      "          [-2.3155e-02,  5.8240e-02, -5.6154e-02,  7.7736e-02, -6.9861e-02]],\n",
      "\n",
      "         [[ 1.4275e-02, -3.2441e-03, -3.6651e-03,  7.1037e-02,  4.6763e-02],\n",
      "          [ 5.7600e-03,  1.3572e-02, -1.4947e-02,  2.6051e-02,  8.1142e-02],\n",
      "          [-2.0482e-02,  5.5250e-02, -7.2443e-02,  2.8012e-02, -3.1207e-02],\n",
      "          [-1.4715e-03, -5.3982e-02,  6.3752e-02,  2.9610e-02,  5.8024e-04],\n",
      "          [ 3.9463e-02,  4.1650e-02,  1.3734e-02,  1.1167e-03,  6.7381e-02]],\n",
      "\n",
      "         [[ 4.8789e-02, -4.4677e-02, -7.4003e-02,  4.4363e-02,  8.0986e-02],\n",
      "          [ 4.0130e-02,  3.9562e-02,  3.4512e-02, -2.1029e-02, -2.7915e-02],\n",
      "          [-6.3834e-02, -2.4387e-02, -1.4504e-02,  5.7465e-02, -7.0608e-02],\n",
      "          [-7.6556e-02, -2.9757e-02,  3.3605e-02,  7.0596e-02, -4.9557e-02],\n",
      "          [ 4.2196e-02,  7.7134e-02, -4.9912e-02, -2.3038e-02, -1.9170e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.3630e-02, -1.3438e-02, -8.1592e-02, -2.2647e-02, -4.3630e-02],\n",
      "          [ 7.5056e-02, -7.8628e-02,  3.0577e-02,  7.8100e-02,  3.9299e-02],\n",
      "          [-4.8752e-02, -7.8232e-02,  7.6498e-02,  1.1018e-02, -1.2985e-02],\n",
      "          [-3.4604e-02, -6.7097e-02,  5.2635e-02,  2.9078e-02,  2.0878e-02],\n",
      "          [-4.7769e-02, -5.3361e-02, -3.6447e-02, -1.8765e-02,  2.4440e-02]],\n",
      "\n",
      "         [[ 6.4604e-02,  3.9393e-02, -1.3709e-02, -4.2854e-02, -2.8870e-02],\n",
      "          [-5.3400e-02, -8.1619e-02, -2.9395e-02, -2.5269e-02,  6.9944e-03],\n",
      "          [ 7.6886e-03, -5.0997e-02, -4.8840e-02,  1.1219e-02, -1.7348e-02],\n",
      "          [ 3.4417e-02,  1.0066e-02, -6.7061e-02,  7.3269e-02, -1.9802e-02],\n",
      "          [-5.5370e-02,  6.2597e-02,  3.6379e-02, -4.2989e-02,  2.3739e-02]],\n",
      "\n",
      "         [[ 4.0049e-02, -3.1742e-02, -7.8740e-02,  5.4600e-02, -8.1300e-02],\n",
      "          [ 5.3483e-02, -5.7731e-02, -6.3432e-02, -4.2647e-02,  7.0573e-02],\n",
      "          [ 5.9365e-02, -2.1800e-02, -4.4767e-02,  4.2044e-02,  4.9230e-02],\n",
      "          [-4.8521e-02,  2.0650e-02, -4.2294e-02, -3.1713e-02,  6.1080e-02],\n",
      "          [ 5.5645e-02,  3.3752e-02, -6.5962e-02, -5.8667e-02,  2.7960e-02]],\n",
      "\n",
      "         [[-7.3385e-02,  3.7592e-02, -6.7279e-02,  3.8425e-02, -1.9986e-03],\n",
      "          [-7.6907e-02,  5.7566e-03,  5.7584e-02,  4.5606e-04,  3.4703e-02],\n",
      "          [ 5.4239e-02, -7.7650e-02,  3.4150e-02, -1.9102e-02,  3.9058e-02],\n",
      "          [-5.7685e-02,  3.7706e-02, -1.4524e-02, -1.0998e-02,  4.0692e-02],\n",
      "          [ 2.9963e-02,  8.3541e-03, -2.2599e-02,  8.0191e-02,  2.0224e-02]],\n",
      "\n",
      "         [[-1.7631e-02,  8.0158e-02,  8.1195e-02, -4.5122e-02, -6.7792e-02],\n",
      "          [-7.5933e-02, -4.2580e-02,  6.0566e-03, -4.5589e-02,  2.8136e-02],\n",
      "          [ 6.8479e-02,  6.3572e-02, -2.0370e-02,  3.6174e-02, -1.9276e-02],\n",
      "          [-5.2450e-02,  4.2040e-02, -1.1259e-02, -2.9589e-02, -4.5536e-03],\n",
      "          [ 1.5217e-02,  3.9443e-02,  7.0183e-03,  5.8805e-02,  2.3672e-02]],\n",
      "\n",
      "         [[ 4.3381e-02, -1.2562e-02, -4.2703e-02,  6.7401e-02, -5.3836e-03],\n",
      "          [-8.1199e-02,  3.7454e-02, -5.6506e-02,  4.0286e-02, -5.6991e-02],\n",
      "          [-2.5350e-02,  6.2518e-02, -7.9163e-02,  6.2870e-02,  3.7904e-02],\n",
      "          [ 3.1711e-02, -2.0651e-02,  6.9484e-02,  3.7429e-04,  6.1002e-02],\n",
      "          [ 3.2754e-02, -4.5691e-02, -4.7530e-02, -6.3048e-02, -1.3000e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6088e-02,  2.1001e-02,  5.0024e-02, -3.1548e-02, -2.4333e-02],\n",
      "          [ 4.0902e-02,  6.0969e-02,  4.7811e-02,  6.1103e-02,  4.8635e-02],\n",
      "          [ 6.2803e-02, -1.0802e-02,  5.8913e-02,  2.6067e-02, -2.1358e-02],\n",
      "          [ 6.6940e-02,  6.7043e-02, -5.4873e-02, -4.0329e-02, -4.3725e-03],\n",
      "          [ 1.6510e-02,  2.7231e-02, -6.9777e-02, -7.4099e-02, -5.1428e-02]],\n",
      "\n",
      "         [[-1.0758e-02, -7.8972e-03, -1.1299e-03,  3.7152e-02,  8.0810e-02],\n",
      "          [-1.5065e-02, -6.7427e-02, -6.6043e-02, -1.8901e-03, -7.6701e-03],\n",
      "          [-4.8449e-02,  5.7259e-02, -5.0574e-02, -6.3942e-02,  6.3286e-02],\n",
      "          [ 4.0123e-02,  4.0694e-02,  4.1302e-02, -7.8064e-02,  5.6591e-02],\n",
      "          [ 1.0254e-02,  4.0801e-02,  1.3548e-02,  3.2399e-02, -1.0287e-04]],\n",
      "\n",
      "         [[ 8.3659e-03,  8.1510e-02,  1.1560e-02, -4.8213e-02, -1.1661e-03],\n",
      "          [-3.9581e-02,  4.9746e-03,  5.9636e-02, -4.7603e-02, -2.7496e-02],\n",
      "          [ 6.7811e-02, -4.9087e-02, -1.6876e-02,  5.6947e-02, -1.3539e-02],\n",
      "          [ 3.5741e-02, -2.6653e-02, -1.3945e-02,  2.3807e-02, -4.5266e-02],\n",
      "          [ 7.4234e-02, -4.0001e-02,  1.8668e-03, -4.2290e-02,  2.7057e-02]],\n",
      "\n",
      "         [[ 6.3187e-02, -2.3735e-02,  7.3616e-02,  5.7002e-02,  3.4451e-02],\n",
      "          [ 6.9904e-02,  1.5055e-02,  8.1319e-02,  1.4609e-02, -1.6020e-02],\n",
      "          [-2.9520e-02,  2.4079e-03, -2.7848e-02, -7.0378e-02, -7.9801e-03],\n",
      "          [-1.2991e-02, -7.6700e-02,  8.9250e-03, -4.1032e-02,  3.0540e-02],\n",
      "          [-1.0918e-02,  3.2166e-02, -4.1578e-02,  3.0144e-02,  7.0222e-02]],\n",
      "\n",
      "         [[ 6.2020e-02,  6.8477e-02, -3.7378e-02,  9.0528e-03, -4.4078e-02],\n",
      "          [-3.1179e-02, -2.2266e-02,  6.9032e-02,  2.4966e-02,  7.2862e-02],\n",
      "          [ 6.8368e-03, -1.3099e-02,  5.9331e-02,  4.4936e-02,  4.8991e-03],\n",
      "          [ 4.6763e-02, -6.0943e-02, -6.8931e-02, -1.7788e-03, -3.1060e-02],\n",
      "          [-1.0654e-02, -7.3268e-02, -2.8227e-02,  3.5435e-02, -1.8578e-02]],\n",
      "\n",
      "         [[-9.9702e-03, -4.0267e-02,  1.5483e-02, -7.7432e-02, -1.5506e-02],\n",
      "          [ 5.6210e-02, -2.6898e-02, -3.0322e-03, -2.9359e-02,  1.0278e-02],\n",
      "          [ 3.5054e-02,  3.4050e-02,  2.0685e-02, -5.7935e-02,  4.7081e-02],\n",
      "          [ 1.4124e-02, -9.9134e-04,  6.5725e-02,  5.7402e-02,  7.9960e-02],\n",
      "          [ 1.8821e-02, -6.2362e-02,  3.4289e-02,  3.0859e-02,  3.1974e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2910e-03, -3.5266e-02, -1.3881e-02,  6.9629e-02, -7.7234e-02],\n",
      "          [ 5.0484e-03,  2.2502e-03,  2.6970e-02, -6.7403e-02, -7.5761e-02],\n",
      "          [-3.9168e-02, -3.0591e-02, -6.8756e-02,  9.9627e-03,  5.7039e-02],\n",
      "          [ 4.6452e-02,  9.9154e-03,  7.0861e-02,  4.5710e-02,  5.5781e-02],\n",
      "          [-4.7938e-02,  3.5315e-02,  1.0914e-02,  5.0637e-02, -2.5918e-02]],\n",
      "\n",
      "         [[-1.5129e-02, -7.1157e-02, -7.5064e-02,  7.4367e-02,  1.4257e-02],\n",
      "          [-6.1278e-02, -1.9386e-02,  7.4185e-02, -1.6952e-02, -2.5955e-02],\n",
      "          [ 3.9361e-02, -5.4200e-02, -5.6096e-02,  1.5317e-02,  5.8927e-02],\n",
      "          [-5.1836e-02,  6.8968e-02,  4.7649e-02,  6.1026e-02,  6.7955e-02],\n",
      "          [-1.8765e-02,  3.0111e-02,  3.9251e-02,  1.0693e-02,  4.4102e-02]],\n",
      "\n",
      "         [[ 6.1863e-02,  5.3102e-03,  4.8339e-02,  5.8730e-02, -7.7761e-02],\n",
      "          [-3.9667e-02,  7.7696e-02, -7.0337e-02, -1.7570e-02,  4.8563e-02],\n",
      "          [ 1.9755e-02,  5.2486e-02, -3.4940e-03, -5.7888e-02, -4.2139e-02],\n",
      "          [ 2.0327e-03,  3.7957e-02,  5.7094e-02,  8.0008e-02,  6.1393e-02],\n",
      "          [-5.5917e-02,  5.2093e-02,  2.5250e-02,  4.9658e-02, -5.3158e-02]],\n",
      "\n",
      "         [[-3.3418e-02,  6.7439e-02, -5.8635e-03, -2.3267e-02, -2.4862e-02],\n",
      "          [ 2.9619e-03,  5.4877e-02, -4.8093e-02,  4.6110e-02, -5.1203e-02],\n",
      "          [-1.6381e-02, -5.0008e-02,  2.8674e-02,  4.2280e-02,  9.9127e-03],\n",
      "          [ 7.2969e-02, -5.7823e-02, -3.6862e-02, -3.3483e-02, -3.5009e-02],\n",
      "          [ 7.7054e-02,  7.2267e-02, -6.0977e-02,  1.3157e-02, -6.7914e-02]],\n",
      "\n",
      "         [[ 6.2440e-02,  5.5326e-02,  1.2204e-02,  2.3499e-02,  3.5921e-02],\n",
      "          [ 1.3146e-02, -2.8831e-03,  4.0975e-02,  4.2327e-02,  1.2370e-02],\n",
      "          [ 7.2293e-02, -1.8970e-02,  3.2987e-02,  6.9739e-02,  5.8229e-02],\n",
      "          [ 6.5497e-02, -8.0986e-02,  4.9277e-02,  4.8964e-02, -5.5670e-02],\n",
      "          [ 2.0736e-02, -2.3666e-02, -3.7196e-02,  7.1169e-02, -2.4119e-03]],\n",
      "\n",
      "         [[ 8.1225e-02,  3.7031e-03, -1.2795e-02,  1.8481e-02,  5.6799e-02],\n",
      "          [ 4.7821e-03,  6.7923e-02, -7.3297e-02,  2.8471e-02,  1.3244e-03],\n",
      "          [-1.2046e-02, -7.2920e-02,  4.1670e-02, -1.6083e-02, -2.8583e-02],\n",
      "          [-6.4767e-02,  6.1746e-02,  4.3677e-02,  4.7380e-02,  2.7925e-02],\n",
      "          [ 2.8967e-02, -2.5400e-02,  6.6208e-02,  2.3823e-02,  1.8091e-03]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0798, -0.0457, -0.0662, -0.0301, -0.0651, -0.0185, -0.0126, -0.0647,\n",
      "         0.0511,  0.0723, -0.0025,  0.0502,  0.0758, -0.0208, -0.0627,  0.0577],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0305,  0.0223,  0.0069,  ...,  0.0268,  0.0464,  0.0208],\n",
      "        [-0.0068, -0.0215,  0.0473,  ..., -0.0239, -0.0069, -0.0331],\n",
      "        [-0.0320, -0.0437,  0.0152,  ..., -0.0458, -0.0127,  0.0031],\n",
      "        ...,\n",
      "        [ 0.0289,  0.0372, -0.0140,  ...,  0.0348,  0.0354,  0.0249],\n",
      "        [-0.0406, -0.0332,  0.0090,  ..., -0.0406,  0.0204, -0.0104],\n",
      "        [-0.0464, -0.0024,  0.0237,  ..., -0.0266, -0.0391, -0.0130]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0328, -0.0471,  0.0302, -0.0255,  0.0133, -0.0342, -0.0411,  0.0222,\n",
      "         0.0195,  0.0454, -0.0426,  0.0401,  0.0207, -0.0293,  0.0317,  0.0329,\n",
      "        -0.0333, -0.0160,  0.0033,  0.0333,  0.0285, -0.0049, -0.0066,  0.0380,\n",
      "         0.0019,  0.0457,  0.0393,  0.0480, -0.0396,  0.0237,  0.0450,  0.0487,\n",
      "        -0.0094,  0.0122,  0.0235,  0.0067,  0.0110, -0.0080,  0.0461, -0.0238,\n",
      "         0.0338,  0.0170,  0.0247,  0.0227,  0.0262, -0.0229,  0.0490, -0.0287,\n",
      "        -0.0368,  0.0106, -0.0436,  0.0225,  0.0059, -0.0324, -0.0230,  0.0055,\n",
      "         0.0057, -0.0365,  0.0142,  0.0392,  0.0353, -0.0379,  0.0191,  0.0266,\n",
      "        -0.0469,  0.0180,  0.0441, -0.0484,  0.0303, -0.0033, -0.0154, -0.0378,\n",
      "        -0.0258, -0.0453, -0.0261, -0.0012, -0.0172,  0.0034, -0.0143,  0.0377,\n",
      "        -0.0314,  0.0223, -0.0160, -0.0493, -0.0320, -0.0077,  0.0249, -0.0201,\n",
      "         0.0013, -0.0115, -0.0046,  0.0457, -0.0126, -0.0004,  0.0186,  0.0414,\n",
      "        -0.0084, -0.0255, -0.0247, -0.0351, -0.0383, -0.0292,  0.0245, -0.0321,\n",
      "        -0.0125,  0.0091, -0.0304, -0.0328, -0.0423,  0.0393,  0.0470,  0.0147,\n",
      "        -0.0084, -0.0011,  0.0168, -0.0124,  0.0467,  0.0202, -0.0154,  0.0146],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0564,  0.0598, -0.0382,  ..., -0.0052, -0.0165,  0.0426],\n",
      "        [ 0.0377,  0.0363, -0.0515,  ...,  0.0540,  0.0079, -0.0013],\n",
      "        [ 0.0439, -0.0315, -0.0555,  ...,  0.0755,  0.0472,  0.0644],\n",
      "        ...,\n",
      "        [-0.0861,  0.0603,  0.0368,  ..., -0.0166, -0.0454, -0.0369],\n",
      "        [-0.0128,  0.0008,  0.0399,  ..., -0.0845,  0.0095,  0.0769],\n",
      "        [-0.0770,  0.0144, -0.0227,  ...,  0.0520, -0.0689, -0.0678]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0692, -0.0733,  0.0401, -0.0097, -0.0179, -0.0722, -0.0328, -0.0509,\n",
      "        -0.0138, -0.0468, -0.0274,  0.0882, -0.0091, -0.0817,  0.0031, -0.0610,\n",
      "        -0.0050,  0.0197, -0.0325, -0.0425, -0.0127, -0.0903, -0.0057,  0.0372,\n",
      "        -0.0536,  0.0221, -0.0869, -0.0863, -0.0368,  0.0843,  0.0784, -0.0706,\n",
      "         0.0414,  0.0345,  0.0522, -0.0663,  0.0700, -0.0768,  0.0857, -0.0827,\n",
      "         0.0079, -0.0470,  0.0105,  0.0521,  0.0353, -0.0091, -0.0022,  0.0156,\n",
      "         0.0644, -0.0103, -0.0800, -0.0865, -0.0396,  0.0389, -0.0767, -0.0120,\n",
      "         0.0319,  0.0461,  0.0304,  0.0450,  0.0262, -0.0483,  0.0725,  0.0115,\n",
      "        -0.0677,  0.0897, -0.0081, -0.0553,  0.0504,  0.0520, -0.0460, -0.0368,\n",
      "        -0.0690,  0.0109,  0.0667, -0.0303, -0.0283, -0.0616,  0.0551, -0.0894,\n",
      "         0.0358, -0.0722,  0.0307, -0.0837], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0330, -0.0826, -0.0488, -0.0572, -0.0792, -0.0480, -0.0713, -0.0697,\n",
      "         -0.0008,  0.0749,  0.1064, -0.0730, -0.0387,  0.0525, -0.0271,  0.0544,\n",
      "         -0.0877,  0.0966, -0.0657,  0.1038,  0.0412,  0.0680,  0.0901,  0.1016,\n",
      "         -0.0637, -0.0850, -0.0125, -0.1063, -0.1064,  0.0175,  0.0907, -0.0337,\n",
      "          0.0637, -0.0305,  0.1043, -0.0527, -0.0834,  0.1057, -0.0690,  0.0375,\n",
      "          0.0863,  0.0271, -0.0293,  0.0261,  0.0580,  0.0946, -0.0164,  0.0190,\n",
      "         -0.0524,  0.0051, -0.0674,  0.0075, -0.0170,  0.0200, -0.0067, -0.0316,\n",
      "          0.0084, -0.0966,  0.0518, -0.0920, -0.0680, -0.0717, -0.0287,  0.0983,\n",
      "         -0.0857, -0.0261, -0.0759,  0.0829,  0.0912, -0.0822, -0.0652,  0.0360,\n",
      "         -0.1053,  0.0907,  0.0501,  0.0099,  0.0611, -0.0801, -0.0182, -0.0903,\n",
      "         -0.0727, -0.0820, -0.0125,  0.0200],\n",
      "        [-0.0103,  0.0108,  0.0494, -0.0624,  0.0086,  0.0819, -0.0018, -0.1024,\n",
      "          0.0733, -0.0710,  0.0068, -0.0772, -0.0832,  0.0920,  0.0359,  0.0190,\n",
      "          0.0039,  0.0329,  0.0137, -0.0375, -0.0395, -0.0011,  0.1021, -0.0720,\n",
      "         -0.0534, -0.0902,  0.0581, -0.0231, -0.0073,  0.0810,  0.1022,  0.0962,\n",
      "          0.0221,  0.0297, -0.0757, -0.0807,  0.1082,  0.1045,  0.0293,  0.0683,\n",
      "          0.0906, -0.0140, -0.0211, -0.0494, -0.0297,  0.0671, -0.0999, -0.0522,\n",
      "          0.0814, -0.1060, -0.1055, -0.0763,  0.0567,  0.0075, -0.0056, -0.0785,\n",
      "         -0.0099,  0.0153,  0.0310, -0.0183, -0.0263,  0.1014, -0.0631, -0.0680,\n",
      "         -0.0310,  0.0606,  0.0270, -0.0420,  0.0789, -0.0886,  0.0233,  0.0219,\n",
      "          0.0210, -0.0664, -0.0798,  0.0203, -0.0509,  0.0239,  0.0722,  0.0120,\n",
      "         -0.0224, -0.0395, -0.0396,  0.0280],\n",
      "        [-0.0203, -0.0706,  0.0938, -0.0201,  0.0933, -0.1085, -0.0237, -0.0130,\n",
      "         -0.0777, -0.0085, -0.0416, -0.0659, -0.0723, -0.0622,  0.0882, -0.1072,\n",
      "          0.0073,  0.0923,  0.1005, -0.0532, -0.0717, -0.0386,  0.1007, -0.0208,\n",
      "          0.0756, -0.0212,  0.0739,  0.0796,  0.1049,  0.0773, -0.0620, -0.0156,\n",
      "          0.0596, -0.0208,  0.1007, -0.0615,  0.0301, -0.0141, -0.0512, -0.0022,\n",
      "         -0.1016, -0.0379, -0.0632,  0.0703,  0.1070, -0.1013, -0.0826,  0.0158,\n",
      "         -0.0859, -0.0765,  0.0273, -0.0226,  0.0181, -0.0110,  0.0133,  0.0923,\n",
      "          0.0003,  0.1037,  0.0326, -0.0066,  0.0401,  0.0599,  0.0253, -0.0435,\n",
      "          0.0015,  0.0748,  0.0359,  0.0819,  0.0597, -0.0704, -0.0896,  0.0250,\n",
      "          0.0370,  0.0815, -0.0010,  0.0154,  0.0510,  0.0540,  0.0803,  0.0052,\n",
      "          0.0436, -0.0514, -0.0456,  0.0370],\n",
      "        [ 0.0583,  0.0757, -0.0784, -0.0292,  0.0119,  0.0531,  0.0892,  0.0466,\n",
      "          0.1044, -0.0732, -0.0019,  0.0323, -0.0732,  0.0830, -0.0382,  0.0653,\n",
      "         -0.0613,  0.0759, -0.1077,  0.0226, -0.0369, -0.0297,  0.1075,  0.0148,\n",
      "          0.0855,  0.1058, -0.0513, -0.0210,  0.0323,  0.0133, -0.0664,  0.0542,\n",
      "         -0.0116,  0.0107, -0.0561, -0.0006,  0.0164, -0.0304,  0.0555, -0.0024,\n",
      "          0.0996,  0.0754, -0.0275,  0.0150,  0.1081, -0.0281,  0.0811, -0.0772,\n",
      "          0.0102, -0.0460, -0.0307,  0.0362, -0.1055, -0.0204,  0.1026,  0.1056,\n",
      "          0.0437,  0.0297, -0.0539, -0.0220,  0.0637, -0.0812,  0.0843,  0.0594,\n",
      "         -0.0621,  0.0485,  0.0977,  0.0171, -0.0434, -0.0214, -0.0034, -0.0483,\n",
      "          0.0140,  0.0939,  0.0921,  0.0151, -0.0532, -0.0192, -0.0471, -0.0124,\n",
      "         -0.0129, -0.0400, -0.0778,  0.0884],\n",
      "        [ 0.0966, -0.0058, -0.0691, -0.0621, -0.0262, -0.0011,  0.0979, -0.0382,\n",
      "          0.0611,  0.0526, -0.0689, -0.0464, -0.0417, -0.0499, -0.0577,  0.0479,\n",
      "          0.0901, -0.0124,  0.0324, -0.0918, -0.0327, -0.0929,  0.0514, -0.1069,\n",
      "         -0.0660, -0.0663,  0.0408, -0.0032,  0.0823, -0.0199, -0.0287, -0.0401,\n",
      "          0.0370,  0.0012, -0.0318, -0.0450,  0.0325,  0.0798,  0.0293,  0.0836,\n",
      "         -0.0345, -0.1051, -0.0926, -0.0077,  0.1045,  0.0166, -0.0325,  0.0750,\n",
      "         -0.0390, -0.1035, -0.0380, -0.0345,  0.1017,  0.0869, -0.0908, -0.0396,\n",
      "          0.0776,  0.0678,  0.1023, -0.0107,  0.0277,  0.0268,  0.0247,  0.1056,\n",
      "         -0.1038,  0.0901, -0.0105, -0.0600, -0.0525, -0.0798,  0.0750, -0.0168,\n",
      "         -0.0509, -0.0555, -0.0420,  0.0069, -0.0613, -0.0230,  0.0171,  0.0109,\n",
      "          0.0003,  0.0782, -0.0262,  0.0769],\n",
      "        [-0.0465,  0.0716,  0.0396,  0.1050, -0.0798,  0.0454,  0.0521,  0.0003,\n",
      "          0.0364,  0.0700,  0.0322,  0.0022,  0.0945,  0.0819,  0.0654,  0.0665,\n",
      "         -0.0283,  0.0141,  0.0472, -0.0285, -0.0187,  0.0222,  0.0772, -0.1057,\n",
      "          0.0161,  0.1081,  0.0522, -0.0560, -0.0545,  0.0356, -0.0909,  0.0885,\n",
      "         -0.0794, -0.0091, -0.1049, -0.0683, -0.1008, -0.0431, -0.0571, -0.0958,\n",
      "          0.0563,  0.1037,  0.0283,  0.0548, -0.1005,  0.0373,  0.0323, -0.1057,\n",
      "          0.0310,  0.1084, -0.1063,  0.0727, -0.0525, -0.0028,  0.0584,  0.0231,\n",
      "         -0.0433,  0.0985, -0.0850, -0.1079,  0.0148, -0.0811, -0.0396, -0.0029,\n",
      "          0.0452, -0.0726, -0.0763,  0.0414, -0.0231, -0.0923,  0.0249,  0.1085,\n",
      "          0.0458, -0.0941,  0.0339, -0.0542,  0.0867, -0.0102, -0.0445, -0.0400,\n",
      "         -0.0300, -0.0743,  0.0561, -0.0113],\n",
      "        [ 0.1068,  0.1065, -0.0211,  0.0050, -0.0744,  0.1079, -0.0215, -0.0581,\n",
      "          0.0230,  0.0446, -0.0370, -0.0940,  0.0459, -0.0842, -0.0655,  0.0535,\n",
      "          0.0849,  0.0901, -0.0777, -0.0173,  0.0159,  0.0568,  0.0179, -0.0977,\n",
      "          0.0112, -0.1090, -0.0689,  0.1047,  0.0086,  0.0990, -0.0810, -0.0253,\n",
      "         -0.0663,  0.1075,  0.0836,  0.0354,  0.0930, -0.0724,  0.0983,  0.0376,\n",
      "          0.0182,  0.0268,  0.0729,  0.0683,  0.0846,  0.0052,  0.0424,  0.0522,\n",
      "          0.0648,  0.0218, -0.0842,  0.0437, -0.0991, -0.0152, -0.0250, -0.0613,\n",
      "          0.0433, -0.0761,  0.0689, -0.0201, -0.0539,  0.0653,  0.0736, -0.0245,\n",
      "         -0.0369, -0.0683,  0.0856,  0.0466,  0.0079, -0.0377,  0.0196,  0.0872,\n",
      "         -0.0748,  0.0354, -0.0077,  0.0636, -0.0142, -0.0291, -0.0256, -0.0317,\n",
      "         -0.0646,  0.0892, -0.0103,  0.0925],\n",
      "        [-0.0243,  0.0632,  0.0069,  0.0288,  0.1068,  0.1018,  0.0742,  0.0747,\n",
      "          0.0511,  0.0933, -0.1045, -0.0095,  0.1000, -0.0549,  0.0050,  0.0346,\n",
      "         -0.0530,  0.0928,  0.0145,  0.1022, -0.0027, -0.0507, -0.0159,  0.0469,\n",
      "          0.0893,  0.0958,  0.0050,  0.0079, -0.0971,  0.0441, -0.0795, -0.0649,\n",
      "          0.0524, -0.1009,  0.0805,  0.0509,  0.0164, -0.0553, -0.0967, -0.0623,\n",
      "         -0.0419,  0.0282, -0.0958, -0.0254,  0.0640, -0.0192,  0.0231,  0.0279,\n",
      "         -0.0382,  0.1065,  0.0519,  0.0254, -0.0916, -0.0002, -0.0618,  0.0687,\n",
      "         -0.0977, -0.0142, -0.0324,  0.1049, -0.0578, -0.0723, -0.0238, -0.0533,\n",
      "          0.0890,  0.0448, -0.0202,  0.0278, -0.0922, -0.0117,  0.0381, -0.0647,\n",
      "         -0.0718, -0.0836, -0.1010,  0.0067,  0.0071,  0.0675, -0.0500,  0.0836,\n",
      "         -0.0928, -0.0834,  0.0975,  0.0256],\n",
      "        [-0.0159, -0.0416, -0.0275, -0.0319,  0.0989,  0.0049,  0.0720, -0.0675,\n",
      "         -0.0967, -0.0605, -0.0636,  0.0015,  0.0571,  0.0836, -0.0859,  0.0600,\n",
      "         -0.0327,  0.0793,  0.0045,  0.0828, -0.1020,  0.0158, -0.0179, -0.0645,\n",
      "          0.0348, -0.0615,  0.0374, -0.1019, -0.0856,  0.0020,  0.0712, -0.0590,\n",
      "          0.1060,  0.1024, -0.0298, -0.0351,  0.0034, -0.0706,  0.0703, -0.0579,\n",
      "          0.0571, -0.0013, -0.0530,  0.0303, -0.0528, -0.0644, -0.0312, -0.0544,\n",
      "         -0.0248, -0.0351, -0.0706,  0.0212,  0.0413,  0.0556, -0.0590,  0.0830,\n",
      "         -0.0845, -0.0407, -0.0695,  0.1030, -0.0671, -0.0471, -0.0531,  0.0150,\n",
      "          0.0276,  0.0947,  0.0687, -0.0009, -0.0132,  0.0718,  0.1014,  0.0297,\n",
      "         -0.0679,  0.0852, -0.0904, -0.0246, -0.0759, -0.1012,  0.0851, -0.0959,\n",
      "          0.0365,  0.0774,  0.1031, -0.0931],\n",
      "        [ 0.0750, -0.1048,  0.0976, -0.0158, -0.0871, -0.0330, -0.0327, -0.0169,\n",
      "         -0.0369,  0.0150, -0.1009,  0.0271, -0.0681, -0.0573, -0.0798,  0.0263,\n",
      "         -0.0491, -0.0662, -0.0164,  0.0881, -0.0069,  0.0821,  0.1031, -0.0676,\n",
      "          0.0675,  0.0597,  0.0118,  0.0453, -0.0475, -0.0936,  0.0185, -0.0209,\n",
      "          0.0889,  0.0673, -0.0997,  0.0261, -0.0410, -0.0968,  0.0888,  0.0663,\n",
      "          0.0148, -0.0652, -0.0008,  0.1022,  0.0877,  0.1003, -0.0061,  0.0328,\n",
      "          0.0450, -0.0284, -0.0288,  0.0845,  0.1015, -0.0559, -0.1028, -0.0357,\n",
      "          0.0961, -0.0783, -0.1074, -0.0844,  0.0128, -0.0213, -0.0638, -0.0062,\n",
      "         -0.0680,  0.0464,  0.0326,  0.1091,  0.0896, -0.0494, -0.0925, -0.0978,\n",
      "         -0.0435,  0.1050, -0.0137, -0.0747,  0.0594, -0.0225,  0.1025, -0.0158,\n",
      "         -0.0348, -0.0047,  0.0827,  0.0801]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0087, -0.0108, -0.0249, -0.0494, -0.0422,  0.0701,  0.0416,  0.0493,\n",
      "        -0.0989,  0.1018], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4275,  1.4027, -0.2897,  ..., -0.6229,  0.3778,  0.2805],\n",
      "          [-1.3784,  1.1511,  1.7643,  ..., -0.3824,  0.5949, -0.4148],\n",
      "          [ 0.4911,  0.8481,  1.4498,  ...,  0.8626,  0.9285, -0.8873],\n",
      "          ...,\n",
      "          [ 1.9511, -1.7569, -0.6933,  ..., -1.0575,  1.4084, -0.8783],\n",
      "          [ 1.2747, -0.2258,  0.4504,  ...,  0.0764,  0.3686, -0.7566],\n",
      "          [ 2.7049,  0.1896,  0.0358,  ...,  0.2842, -1.2235,  1.3002]]]])\n",
      "torch.Size([1, 1, 32, 32])\n",
      "tensor([[-0.0074,  0.0373,  0.0268,  0.0352, -0.0351,  0.0945,  0.0595, -0.0143,\n",
      "         -0.0348,  0.1634]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "print(input)\n",
    "print(input.size())\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0719, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x112651748>\n",
      "<AddmmBackward object at 0x112651710>\n",
      "<AccumulateGrad object at 0x112651748>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0149,  0.0150,  0.0255, -0.0072,  0.0089, -0.0057])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop\n",
    "optimizer.zero_grad() # zero the gradient buffers. Because gradients are accumulated. what does this mean?\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # Does the update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
